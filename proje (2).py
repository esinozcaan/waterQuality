# -*- coding: utf-8 -*-
"""proje.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eOFyYPNQP1_334KTGmEfsEBYVxA9iEFg

Esin Özcan 030121039
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.linear_model import LinearRegression, Lasso
from sklearn.feature_selection import RFE
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.cluster import KMeans
from scipy.stats import mode
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv("/content/waterquality.csv")

"""Bu veri seti yaklaşık 20 yılda iki haftada bir alınan örneklerle oluşturulmuş. Amaç zamana göre su kalitesini kayıt altında tutmak.Tuz oranı, oksijen seviyesi, pH, berraklık, su seviyesi, su sıcaklığı ve hava sıcaklığı gibi parametrelerden yararlanılmıştır."""

df.head()

"""Aykırı değerleri bulmak için:"""

df.isnull().sum()

"""Veri setinin boyutlarını öğrenmek için:"""

df.shape

"""Veri Setinde eksik verileri medyan değerlerle doldurma:"""

for i in df.columns[1:]:
    df[i] = df[i].fillna(df[i].median())

df.isnull().sum()

"""Bilinmeyen tarihli satırları silmek için:"""

df.dropna(inplace=True)

df.isnull().sum()

df.head()

"""Normalizasyon için tarih sütununu çıkarma:"""

df_features = df.drop(columns=['Date'])

"""**Min-Max Normalizasyonu**"""

min_max_scaler = MinMaxScaler()

df_min_max_normalized = pd.DataFrame(min_max_scaler.fit_transform(df_features), columns=df_features.columns)

print(df_min_max_normalized)

"""**Z-Score normalizasyonu**"""

//standard_scaler = StandardScaler()

//df_standardized = pd.DataFrame(standard_scaler.fit_transform(df_features), columns=df_features.columns)

//print(df_standardized)

"""**Min-Max normalizasyonu uygulanmış veri seti üzerinde korelasyon mantrisi gösterme:**

Korelasyon matrisi, değişkenler arasındaki doğrusal ilişkileri gösterir. Özellikler arasında yüksek korelasyon varsa, bu özelliklerden biri diğerinin yerini tutabileceğinden, bu özelliklerden birini çıkarabilirsiniz.
"""

df = pd.DataFrame(df_min_max_normalized)

"""Korelasyon matrisini hesaplama:"""

corr_matrix = df_min_max_normalized.corr()

plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.show()

bins = [0, 10, 20, 30, np.inf]
labels = ['Low', 'Medium', 'High', 'Very High']
df_min_max_normalized['WaterTemp (C)'] = pd.cut(df_min_max_normalized['WaterTemp (C)'], bins=bins, labels=labels)

corr_matrix = df_min_max_normalized.drop(columns=['WaterTemp (C)']).corr()
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.show()

X = df_min_max_normalized.drop('WaterTemp (C)', axis=1)
y = df_min_max_normalized['WaterTemp (C)']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


rf_model = RandomForestClassifier(random_state=42)

df.isnull().sum()

rf_model.fit(X_train, y_train)
y_train_pred = rf_model.predict(X_train)

y_test_pred = rf_model.predict(X_test)

print(confusion_matrix(y_train, y_train_pred))
print(classification_report(y_train, y_train_pred))

print(confusion_matrix(y_test, y_test_pred))
print(classification_report(y_test, y_test_pred))

"""**Normalize edilmiş veri setine RFE uygulama**

Recursive Feature Elimination (RFE) yöntemi, özelliklerin önemine göre sıralanıp iteratif olarak en az önemli olanların çıkarılmasıyla çalışır.
"""

model = LinearRegression()

"""Hedef değişkenimi Su sıcaklığını tahmin etmeye yönelik belirledim"""

X=df.drop(columns=['WaterTemp (C)'])
y=df['WaterTemp (C)']

scaler = MinMaxScaler()
X_normalized = scaler.fit_transform(X)

"""En iyi 3 özelliği seçmek için:"""

rfe = RFE(model, n_features_to_select=3)
fit = rfe.fit(X_normalized, y)

"""Num Features: Kaç özellik seçtiğimizin sayısı;
Selected Features: Hangi özelliklerin True(seçilebilir) hangilerinin False(seçilemez) olduğu;
Feature Ranking:Özellikler için önem sıralaması.
"""

print("Num Features: %s" % (fit.n_features_))
print("Selected Features: %s" % (fit.support_))
print("Feature Ranking: %s" % (fit.ranking_))

"""Son olarak hangi özelliklerin seçildiği:"""

selected_features = X.columns[fit.support_]
print("RFE için seçilen özellikler:", selected_features)

"""Seçilen özellikler kullanılarak veri seti güncellenmesi:"""

X_selected = X[selected_features]

"""Eğitim ve test veri setlerine ayırma:"""

X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)

"""**KNN regresyon modeli ile eğitim:**"""

knn = KNeighborsRegressor(n_neighbors=3)
knn.fit(X_train, y_train)

"""Tahmin yapma ve performans değerlendirme:"""

y_pred = knn.predict(X_test)

"""Mean Squared Error (MSE) ve R^2 Score ile modelin performansını değerlendirme: (Karışıklık matrisi sınıflandırma yapılmadığı için kullanılamadı)"""

print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))

X_selected = X[selected_features]

kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(X_selected)

bins = [0, 0.25, 0.5, 1]
labels = [0, 1, 2]
y_binned = pd.cut(y, bins=bins, labels=labels)
print(y_binned.isna().sum())
y_binned = y_binned.dropna()
X_selected = X_selected.iloc[y_binned.index]

X_train, X_test, y_train, y_test = train_test_split(X_selected, y_binned, test_size=0.2, random_state=42)

y_kmeans = kmeans.predict(X_test)
def relabel_clusters(y_true, y_clusters):
    labels = np.zeros_like(y_clusters)
    for i in range(3):
        mask = (y_clusters == i)
        labels[mask] = mode(y_true[mask])[0]
    return labels

y_kmeans_relabelled = relabel_clusters(y_test, y_kmeans)
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_kmeans_relabelled))
print("\nClassification Report:")
print(classification_report(y_test, y_kmeans_relabelled))

pca = PCA(n_components=2)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

nb_model = GaussianNB()
nb_model.fit(X_train_pca, y_train)

lda_model = LinearDiscriminantAnalysis()
lda_model.fit(X_train_pca, y_train)

nb_y_pred = nb_model.predict(X_test_pca)
print(confusion_matrix(y_test, nb_y_pred))
print(classification_report(y_test, nb_y_pred))

lda_y_pred = lda_model.predict(X_test_pca)
print(confusion_matrix(y_test, lda_y_pred))
print(classification_report(y_test, lda_y_pred))

"""**Lasso Regresyonuna göre min-max ile normalize edilmiş veri seti üzerinde özellik seçimi:**

Lasso, özelliklerin katsayılarını sıfıra yaklaştırarak gereksiz özellikleri eleme eğilimindedir. Katsayısı 0 olan özellik modelden çıkarılır. Bu nedenle, sıfırdan farklı olan katsayılara sahip olan özellikler, model tarafından seçilen önemli özellikler olarak kabul edilir.
"""

scaler = MinMaxScaler()
X_normalized = scaler.fit_transform(X)

"""Lasso katsayısını 0.01 olarak belirledik ve hedef değişkenimiz yine su sıcaklığı."""

lasso = Lasso(alpha=0.01)
lasso.fit(X_normalized, df['WaterTemp (C)'] )

"""Lasso regresyonu uygulandıktan sonra katsayılar alındı ve 0 olmayanlar seçildi:"""

selected_features = X.columns[lasso.coef_ != 0]
print("Seçilen Özellikler:", selected_features)

df.head()

"""Seçilen özellikleri kullanarak veri setini güncelleme:"""

X_selected = X[selected_features]

"""**K-means kümeleri oluşturma:**"""

kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(X_selected)

"""4. Hedef değişkeni kategorilere ayırma (sınıflandırma için):"""

bins = [0, 0.25, 0.5, 1]
labels = [0, 1, 2]
y_binned = pd.cut(y, bins=bins, labels=labels)

"""NaN değerleri kontrol etme ve kaldırma:(sınıflandırma sırasında oluşan)"""

print(y_binned.isna().sum())
y_binned = y_binned.dropna()
X_selected = X_selected.iloc[y_binned.index]

"""Eğitim ve test veri setlerine ayırma"""

X_train, X_test, y_train, y_test = train_test_split(X_selected, y_binned, test_size=0.2, random_state=42)

"""Test setinde kümeleri tahmin etme:"""

y_kmeans = kmeans.predict(X_test)

"""K-means kümelerini yeniden etiketleme
Her bir K-means kümesi için en yaygın gerçek etiketi bulma
"""

def relabel_clusters(y_true, y_clusters):
    labels = np.zeros_like(y_clusters)
    for i in range(3):
        mask = (y_clusters == i)
        labels[mask] = mode(y_true[mask])[0]
    return labels

"""Yeniden etiketleme"""

y_kmeans_relabelled = relabel_clusters(y_test, y_kmeans)

"""K-means sonuçlarını etiketlerle karşılaştırma ve karışıklık matrisi:"""

y_kmeans_relabelled = relabel_clusters(y_test, y_kmeans)
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_kmeans_relabelled))
print("\nClassification Report:")
print(classification_report(y_test, y_kmeans_relabelled))

pca = PCA(n_components=2)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

nb_model = GaussianNB()
nb_model.fit(X_train_pca, y_train)

lda_model = LinearDiscriminantAnalysis()
lda_model.fit(X_train_pca, y_train)

nb_y_pred = nb_model.predict(X_test_pca)
print(confusion_matrix(y_test, nb_y_pred))
print(classification_report(y_test, nb_y_pred))

lda_y_pred = lda_model.predict(X_test_pca)
print(confusion_matrix(y_test, lda_y_pred))
print(classification_report(y_test, lda_y_pred))